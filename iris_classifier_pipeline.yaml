# PIPELINE DEFINITION
# Name: iris-classifier-pipeline
# Description: Defines the complete pipeline for classification.
components:
  comp-evaluate-model:
    executorLabel: exec-evaluate-model
    inputDefinitions:
      artifacts:
        model_file:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        test_features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        test_labels:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        evaluation_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-fetch-data:
    executorLabel: exec-fetch-data
    outputDefinitions:
      artifacts:
        data_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-process-features:
    executorLabel: exec-process-features
    inputDefinitions:
      artifacts:
        raw_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        test_features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        test_labels:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_labels:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      artifacts:
        train_features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_labels:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        model_output:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-evaluate-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluate_model(\n    test_features: Input[Dataset],\n    test_labels:\
          \ Input[Dataset],\n    model_file: Input[Model],\n    evaluation_output:\
          \ Output[Dataset]\n):\n    \"\"\"Evaluates model performance and generates\
          \ a report.\"\"\"\n    import subprocess\n    subprocess.run([\"pip\", \"\
          install\", \"pandas\", \"scikit-learn\", \"seaborn\", \"joblib\"], check=True)\n\
          \n    import pandas as pd\n    import seaborn as sns\n    import matplotlib.pyplot\
          \ as plt\n    from sklearn.metrics import classification_report, confusion_matrix\n\
          \    from joblib import load\n\n    X_test = pd.read_csv(test_features.path)\n\
          \    y_true = pd.read_csv(test_labels.path)['label']\n    model = load(model_file.path)\n\
          \n    y_pred = model.predict(X_test)\n\n    metrics = classification_report(y_true,\
          \ y_pred, output_dict=True)\n    conf_matrix = confusion_matrix(y_true,\
          \ y_pred)\n\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(conf_matrix,\
          \ annot=True, fmt='d', cmap='YlOrRd')\n    plt.title('Confusion Matrix Heatmap')\n\
          \    plt.xlabel('Predicted Class')\n    plt.ylabel('Actual Class')\n\n \
          \   results = {\n        'metrics': metrics,\n        'confusion_matrix':\
          \ conf_matrix.tolist()\n    }\n    pd.DataFrame([results]).to_json(evaluation_output.path)\n\
          \n"
        image: python:3.9
    exec-fetch-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - fetch_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef fetch_data(data_output: Output[Dataset]):\n    \"\"\"Loads and\
          \ saves the dataset.\"\"\"\n    import subprocess\n    subprocess.run([\"\
          pip\", \"install\", \"pandas\", \"scikit-learn\"], check=True)\n\n    from\
          \ sklearn.datasets import load_iris\n    import pandas as pd\n\n    iris\
          \ = load_iris()\n    dataset = pd.DataFrame(\n        iris.data,\n     \
          \   columns=[col.replace(' ', '_').lower() for col in iris.feature_names]\n\
          \    )\n    dataset['label'] = iris.target\n\n    dataset.to_csv(data_output.path,\
          \ index=False)\n\n"
        image: python:3.9
    exec-process-features:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - process_features
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef process_features(\n    raw_data: Input[Dataset],\n    train_features:\
          \ Output[Dataset],\n    test_features: Output[Dataset],\n    train_labels:\
          \ Output[Dataset],\n    test_labels: Output[Dataset]\n):\n    \"\"\"Prepares\
          \ data by normalizing and splitting into training/testing sets.\"\"\"\n\
          \    import subprocess\n    subprocess.run([\"pip\", \"install\", \"pandas\"\
          , \"scikit-learn\"], check=True)\n\n    import pandas as pd\n    import\
          \ numpy as np\n    from sklearn.preprocessing import RobustScaler\n    from\
          \ sklearn.model_selection import train_test_split\n\n    dataset = pd.read_csv(raw_data.path)\n\
          \    assert dataset.notna().all().all(), \"Dataset contains missing values\"\
          \n\n    features = dataset.drop(columns=['label'])\n    target = dataset['label']\n\
          \n    scaler = RobustScaler()\n    normalized_features = scaler.fit_transform(features)\n\
          \n    X_train, X_test, y_train, y_test = train_test_split(\n        normalized_features,\
          \ \n        target,\n        test_size=0.25,\n        random_state=42,\n\
          \        stratify=target\n    )\n\n    pd.DataFrame(X_train, columns=features.columns).to_csv(train_features.path,\
          \ index=False)\n    pd.DataFrame(X_test, columns=features.columns).to_csv(test_features.path,\
          \ index=False)\n    pd.DataFrame(y_train, columns=['label']).to_csv(train_labels.path,\
          \ index=False)\n    pd.DataFrame(y_test, columns=['label']).to_csv(test_labels.path,\
          \ index=False)\n\n"
        image: python:3.9
    exec-train-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_model(\n    train_features: Input[Dataset],\n    train_labels:\
          \ Input[Dataset],\n    model_output: Output[Model]\n):\n    \"\"\"Trains\
          \ and saves a classification model.\"\"\"\n    import subprocess\n    subprocess.run([\"\
          pip\", \"install\", \"pandas\", \"scikit-learn\", \"joblib\"], check=True)\n\
          \n    import pandas as pd\n    from sklearn.linear_model import LogisticRegression\n\
          \    from joblib import dump\n\n    X = pd.read_csv(train_features.path)\n\
          \    y = pd.read_csv(train_labels.path)['label']\n\n    model = LogisticRegression(\n\
          \        class_weight='balanced',\n        max_iter=1000,\n        random_state=42,\n\
          \        multi_class='multinomial'\n    )\n    model.fit(X, y)\n\n    dump(model,\
          \ model_output.path)\n\n"
        image: python:3.9
pipelineInfo:
  description: Defines the complete pipeline for classification.
  name: iris-classifier-pipeline
root:
  dag:
    tasks:
      evaluate-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-model
        dependentTasks:
        - process-features
        - train-model
        inputs:
          artifacts:
            model_file:
              taskOutputArtifact:
                outputArtifactKey: model_output
                producerTask: train-model
            test_features:
              taskOutputArtifact:
                outputArtifactKey: test_features
                producerTask: process-features
            test_labels:
              taskOutputArtifact:
                outputArtifactKey: test_labels
                producerTask: process-features
        taskInfo:
          name: evaluate-model
      fetch-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-fetch-data
        taskInfo:
          name: fetch-data
      process-features:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-process-features
        dependentTasks:
        - fetch-data
        inputs:
          artifacts:
            raw_data:
              taskOutputArtifact:
                outputArtifactKey: data_output
                producerTask: fetch-data
        taskInfo:
          name: process-features
      train-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-model
        dependentTasks:
        - process-features
        inputs:
          artifacts:
            train_features:
              taskOutputArtifact:
                outputArtifactKey: train_features
                producerTask: process-features
            train_labels:
              taskOutputArtifact:
                outputArtifactKey: train_labels
                producerTask: process-features
        taskInfo:
          name: train-model
schemaVersion: 2.1.0
sdkVersion: kfp-2.12.1
